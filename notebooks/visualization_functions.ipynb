{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a5e46d7",
   "metadata": {},
   "source": [
    "# Visualization Functions Library\n",
    "\n",
    "Notebook này chứa tất cả các hàm visualization từ `visualize.py`, được chuyển đổi thành dạng interactive và có thêm documentation chi tiết.\n",
    "\n",
    "## Nội dung:\n",
    "1. Basic Plotting Functions\n",
    "   - ROUGE scores visualization\n",
    "   - BLEU scores visualization\n",
    "   - Training metrics visualization\n",
    "2. Advanced Comparisons\n",
    "   - Radar charts\n",
    "   - Comprehensive comparisons\n",
    "3. Interactive Widgets\n",
    "4. Export Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646bac0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import các thư viện cần thiết\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual, widgets\n",
    "\n",
    "# Thêm project path\n",
    "BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath('__file__')))\n",
    "if BASE_DIR not in sys.path:\n",
    "    sys.path.insert(0, BASE_DIR)\n",
    "\n",
    "from src.config import FIGURES_DIR, TABLES_DIR, ROUGE_METRICS, REPORT_TITLE\n",
    "\n",
    "# Set style cho matplotlib\n",
    "plt.style.use('seaborn')\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "plt.rcParams['savefig.dpi'] = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86e29e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic plotting functions\n",
    "def plot_rouge_scores(results_df: pd.DataFrame, save_fig: bool = False, filename: str = \"rouge_scores.png\"):\n",
    "    \"\"\"\n",
    "    Generates interactive bar chart comparing ROUGE scores across different methods.\n",
    "    \n",
    "    Args:\n",
    "        results_df: DataFrame with columns ['Method', 'ROUGE-1', 'ROUGE-2', 'ROUGE-L']\n",
    "        save_fig: Whether to save the figure to disk\n",
    "        filename: Name of the file to save\n",
    "    \"\"\"\n",
    "    if results_df.empty:\n",
    "        print(\"No data to plot for ROUGE scores.\")\n",
    "        return\n",
    "    \n",
    "    # Create plotly figure\n",
    "    fig = go.Figure()\n",
    "    methods = results_df['Method'].values\n",
    "    \n",
    "    for metric in ['ROUGE-1', 'ROUGE-2', 'ROUGE-L']:\n",
    "        fig.add_trace(go.Bar(\n",
    "            name=metric,\n",
    "            x=methods,\n",
    "            y=results_df[metric],\n",
    "            text=results_df[metric].round(3),\n",
    "            textposition='auto',\n",
    "        ))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title='ROUGE Scores Comparison',\n",
    "        xaxis_title='Method',\n",
    "        yaxis_title='Score',\n",
    "        barmode='group',\n",
    "        width=900,\n",
    "        height=500\n",
    "    )\n",
    "    \n",
    "    if save_fig:\n",
    "        if not os.path.exists(FIGURES_DIR):\n",
    "            os.makedirs(FIGURES_DIR)\n",
    "        plt.savefig(os.path.join(FIGURES_DIR, filename), bbox_inches='tight')\n",
    "        print(f\"Figure saved as {filename}\")\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def plot_training_metrics(results_df: pd.DataFrame, save_fig: bool = False, filename: str = \"training_metrics.png\"):\n",
    "    \"\"\"\n",
    "    Creates subplot comparing training time, VRAM usage, and trainable parameters.\n",
    "    \n",
    "    Args:\n",
    "        results_df: DataFrame with training metrics\n",
    "        save_fig: Whether to save the figure\n",
    "        filename: Name of the file to save\n",
    "    \"\"\"\n",
    "    fig = make_subplots(rows=1, cols=3, \n",
    "                        subplot_titles=('Training Time (minutes)', 'VRAM Usage (GB)', \n",
    "                                      'Trainable Parameters (M)'))\n",
    "    \n",
    "    metrics = {\n",
    "        'Training Time': 'Training Time (min)',\n",
    "        'VRAM': 'VRAM (GB)',\n",
    "        'Parameters': 'Trainable Params (num)'\n",
    "    }\n",
    "    \n",
    "    for idx, (name, col) in enumerate(metrics.items(), 1):\n",
    "        values = results_df[col]\n",
    "        if name == 'Parameters':\n",
    "            values = values / 1e6  # Convert to millions\n",
    "            \n",
    "        fig.add_trace(\n",
    "            go.Bar(name=name, x=results_df['Method'], y=values,\n",
    "                  text=values.round(1), textposition='auto'),\n",
    "            row=1, col=idx\n",
    "        )\n",
    "    \n",
    "    fig.update_layout(height=400, width=1200, showlegend=False,\n",
    "                     title_text=\"Training Metrics Comparison\")\n",
    "    fig.update_xaxes(tickangle=45)\n",
    "    \n",
    "    if save_fig:\n",
    "        if not os.path.exists(FIGURES_DIR):\n",
    "            os.makedirs(FIGURES_DIR)\n",
    "        plt.savefig(os.path.join(FIGURES_DIR, filename), bbox_inches='tight')\n",
    "        print(f\"Figure saved as {filename}\")\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215b745e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced plotting functions\n",
    "def plot_radar_comparison(results_df: pd.DataFrame, metrics: list = None, save_fig: bool = False, \n",
    "                         filename: str = \"radar_comparison.png\"):\n",
    "    \"\"\"\n",
    "    Creates a radar/spider chart comparing methods across multiple metrics.\n",
    "    \n",
    "    Args:\n",
    "        results_df: DataFrame with evaluation results\n",
    "        metrics: List of metrics to include (defaults to ROUGE metrics)\n",
    "        save_fig: Whether to save the figure\n",
    "        filename: Name of the file to save\n",
    "    \"\"\"\n",
    "    if metrics is None:\n",
    "        metrics = ['ROUGE-1', 'ROUGE-2', 'ROUGE-L', 'BLEU']\n",
    "    \n",
    "    fig = go.Figure()\n",
    "    for method in results_df['Method']:\n",
    "        method_data = results_df[results_df['Method'] == method]\n",
    "        fig.add_trace(go.Scatterpolar(\n",
    "            r=method_data[metrics].values[0],\n",
    "            theta=metrics,\n",
    "            fill='toself',\n",
    "            name=method\n",
    "        ))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        polar=dict(\n",
    "            radialaxis=dict(\n",
    "                visible=True,\n",
    "                range=[0, max([results_df[m].max() for m in metrics])]\n",
    "            )),\n",
    "        showlegend=True,\n",
    "        title='Method Comparison Across Metrics',\n",
    "        width=800,\n",
    "        height=600\n",
    "    )\n",
    "    \n",
    "    if save_fig:\n",
    "        if not os.path.exists(FIGURES_DIR):\n",
    "            os.makedirs(FIGURES_DIR)\n",
    "        plt.savefig(os.path.join(FIGURES_DIR, filename), bbox_inches='tight')\n",
    "        print(f\"Figure saved as {filename}\")\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def plot_comprehensive_comparison(results_df: pd.DataFrame, save_fig: bool = False, \n",
    "                                filename: str = \"comprehensive_comparison.png\"):\n",
    "    \"\"\"\n",
    "    Creates a comprehensive visualization comparing all aspects of the methods.\n",
    "    \n",
    "    Args:\n",
    "        results_df: DataFrame with all metrics\n",
    "        save_fig: Whether to save the figure\n",
    "        filename: Name of the file to save\n",
    "    \"\"\"\n",
    "    # Create figure with secondary y-axis\n",
    "    fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "    \n",
    "    # Add ROUGE scores as grouped bars\n",
    "    for metric in ['ROUGE-1', 'ROUGE-2', 'ROUGE-L']:\n",
    "        fig.add_trace(\n",
    "            go.Bar(name=metric, x=results_df['Method'], y=results_df[metric],\n",
    "                  text=results_df[metric].round(3), textposition='auto'),\n",
    "            secondary_y=False,\n",
    "        )\n",
    "    \n",
    "    # Add training time as line on secondary axis\n",
    "    fig.add_trace(\n",
    "        go.Scatter(name='Training Time', x=results_df['Method'], \n",
    "                  y=results_df['Training Time (min)'],\n",
    "                  line=dict(color='red', width=2),\n",
    "                  mode='lines+markers'),\n",
    "        secondary_y=True,\n",
    "    )\n",
    "    \n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        title='Comprehensive Method Comparison',\n",
    "        barmode='group',\n",
    "        width=1000,\n",
    "        height=600\n",
    "    )\n",
    "    \n",
    "    # Set y-axes titles\n",
    "    fig.update_yaxes(title_text=\"ROUGE Scores\", secondary_y=False)\n",
    "    fig.update_yaxes(title_text=\"Training Time (minutes)\", secondary_y=True)\n",
    "    \n",
    "    if save_fig:\n",
    "        if not os.path.exists(FIGURES_DIR):\n",
    "            os.makedirs(FIGURES_DIR)\n",
    "        plt.savefig(os.path.join(FIGURES_DIR, filename), bbox_inches='tight')\n",
    "        print(f\"Figure saved as {filename}\")\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5d8abb",
   "metadata": {},
   "source": [
    "## Example Usage\n",
    "\n",
    "Dưới đây là các ví dụ sử dụng các hàm visualization với dữ liệu mẫu từ `evaluation_results.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f9e064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load evaluation results\n",
    "results_path = os.path.join(TABLES_DIR, 'evaluation_results.csv')\n",
    "df = pd.read_csv(results_path)\n",
    "\n",
    "# Display sample of the data\n",
    "print(\"Sample of evaluation results:\")\n",
    "display(df.head())\n",
    "\n",
    "# Create and display plots\n",
    "print(\"\\nROUGE Scores Comparison:\")\n",
    "fig_rouge = plot_rouge_scores(df)\n",
    "fig_rouge.show()\n",
    "\n",
    "print(\"\\nTraining Metrics Comparison:\")\n",
    "fig_metrics = plot_training_metrics(df)\n",
    "fig_metrics.show()\n",
    "\n",
    "print(\"\\nRadar Chart Comparison:\")\n",
    "fig_radar = plot_radar_comparison(df)\n",
    "fig_radar.show()\n",
    "\n",
    "print(\"\\nComprehensive Comparison:\")\n",
    "fig_comprehensive = plot_comprehensive_comparison(df)\n",
    "fig_comprehensive.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99a773f",
   "metadata": {},
   "source": [
    "## Interactive Widgets\n",
    "\n",
    "Dưới đây là một số widget tương tác để tùy chỉnh các visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c425c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interactive_plot(metrics=None, methods=None, plot_type='bar', \n",
    "                  figure_width=800, figure_height=500):\n",
    "    \"\"\"\n",
    "    Interactive plotting function with widgets\n",
    "    \"\"\"\n",
    "    if metrics is None:\n",
    "        metrics = ['ROUGE-1', 'ROUGE-2', 'ROUGE-L']\n",
    "    if methods is None:\n",
    "        methods = df['Method'].tolist()\n",
    "        \n",
    "    if not isinstance(metrics, list):\n",
    "        metrics = [metrics]\n",
    "    if not isinstance(methods, list):\n",
    "        methods = [methods]\n",
    "        \n",
    "    df_filtered = df[df['Method'].isin(methods)]\n",
    "    \n",
    "    if plot_type == 'bar':\n",
    "        fig = go.Figure()\n",
    "        for metric in metrics:\n",
    "            fig.add_trace(go.Bar(\n",
    "                name=metric,\n",
    "                x=df_filtered['Method'],\n",
    "                y=df_filtered[metric],\n",
    "                text=df_filtered[metric].round(3),\n",
    "                textposition='auto',\n",
    "            ))\n",
    "        fig.update_layout(barmode='group')\n",
    "    else:  # radar plot\n",
    "        fig = go.Figure()\n",
    "        for method in methods:\n",
    "            method_data = df[df['Method'] == method]\n",
    "            fig.add_trace(go.Scatterpolar(\n",
    "                r=method_data[metrics].values[0],\n",
    "                theta=metrics,\n",
    "                fill='toself',\n",
    "                name=method\n",
    "            ))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=f'Comparison of {\", \".join(metrics)}',\n",
    "        width=figure_width,\n",
    "        height=figure_height\n",
    "    )\n",
    "    fig.show()\n",
    "\n",
    "# Create widgets\n",
    "metric_options = ['ROUGE-1', 'ROUGE-2', 'ROUGE-L', 'BLEU', \n",
    "                 'Training Time (min)', 'VRAM (GB)', 'Trainable Params (num)']\n",
    "method_options = df['Method'].unique().tolist()\n",
    "\n",
    "metrics_widget = widgets.SelectMultiple(\n",
    "    options=metric_options,\n",
    "    value=['ROUGE-1', 'ROUGE-2', 'ROUGE-L'],\n",
    "    description='Metrics:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "methods_widget = widgets.SelectMultiple(\n",
    "    options=method_options,\n",
    "    value=method_options[:2],  # Default to first two methods\n",
    "    description='Methods:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "plot_type_widget = widgets.RadioButtons(\n",
    "    options=['bar', 'radar'],\n",
    "    value='bar',\n",
    "    description='Plot Type:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "width_widget = widgets.IntSlider(\n",
    "    value=800,\n",
    "    min=400,\n",
    "    max=1200,\n",
    "    step=100,\n",
    "    description='Width:',\n",
    ")\n",
    "\n",
    "height_widget = widgets.IntSlider(\n",
    "    value=500,\n",
    "    min=300,\n",
    "    max=800,\n",
    "    step=100,\n",
    "    description='Height:',\n",
    ")\n",
    "\n",
    "# Create interactive plot\n",
    "interact(interactive_plot, \n",
    "        metrics=metrics_widget,\n",
    "        methods=methods_widget,\n",
    "        plot_type=plot_type_widget,\n",
    "        figure_width=width_widget,\n",
    "        figure_height=height_widget);"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
